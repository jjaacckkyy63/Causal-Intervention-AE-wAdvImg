{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import seaborn as sns\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "from glob import glob\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose which GPU to use\n",
    "gpu_no = 0\n",
    "torch.cuda.set_device(gpu_no)\n",
    "use_gpu = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean dataset (optional)\n",
    "for img in glob(\"/home/jovyan/EJ/causality/chexnet/database/images/*png\"):\n",
    "    try:\n",
    "        im = Image.open(img)\n",
    "    except OSError as e:\n",
    "        os.remove(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default database path\n",
    "data_dir = 'database/'\n",
    "trans = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "image_datasets = datasets.ImageFolder(data_dir,trans)\n",
    "dataloders = torch.utils.data.DataLoader(image_datasets, batch_size=8,\n",
    "                                             shuffle=True)\n",
    "#check database sizes\n",
    "dataset_sizes = len(image_datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "densenet121 = models.densenet121(pretrained=False)\n",
    "kernelCount = densenet121.classifier.in_features\n",
    "densenet121.classifier = nn.Sequential(nn.Linear(kernelCount, 14), nn.Softmax())\n",
    "if use_gpu:                 \n",
    "    densenet121 = densenet121.cuda()       \n",
    "densenet121 = densenet121.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"models/m-25012018-123527.pth.tar\")\n",
    "from collections import OrderedDict\n",
    "new_state_dict = OrderedDict()\n",
    "checkpoint[\"state_dict\"]\n",
    "for k, v in checkpoint[\"state_dict\"].items():\n",
    "    name = k[19:] # remove module.`\n",
    "    name = name.replace(\"norm.1\",\"norm1\")\n",
    "    name = name.replace(\"norm.2\",\"norm2\")\n",
    "    name = name.replace(\"conv.1\",\"conv1\")\n",
    "    name = name.replace(\"conv.2\",\"conv2\")\n",
    "    new_state_dict[name] = v\n",
    "densenet121.load_state_dict(new_state_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_gpu:             \n",
    "    densenet121 = densenet121.cuda()       \n",
    "densenet121 = densenet121.float()\n",
    "summary(densenet121,(3,224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freeze_layer = 6\n",
    "f_model = list(densenet121.features.children())[:freeze_layer]\n",
    "f_model = nn.Sequential(*f_model)\n",
    "r_model = list(densenet121.features.children())[freeze_layer:len(list(densenet121.features.children()))]\n",
    "r_model = nn.Sequential(*r_model)\n",
    "cls_model = nn.Sequential(*list(densenet121.classifier.children()))\n",
    "r_freeze = list(densenet121.features.children())[freeze_layer:len(list(densenet121.features.children()))]\n",
    "r_freeze = nn.Sequential(*r_freeze)\n",
    "cls_freeze = nn.Sequential(*list(densenet121.classifier.children()))\n",
    "\n",
    "for param in r_freeze.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in cls_freeze.parameters():\n",
    "    param.requires_grad = False\n",
    "print(f_model)\n",
    "print(cls_model)\n",
    "# densenet121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae1 = nn.Conv2d(in_channels=128,out_channels=32,kernel_size=(3,3),padding=(1, 1))\n",
    "hd1 = nn.Conv2d(in_channels=32,out_channels=16,kernel_size=(3,3),padding=(1, 1))\n",
    "hd2 = nn.Conv2d(in_channels=16,out_channels=32,kernel_size=(3,3),padding=(1, 1))\n",
    "ae2 = nn.Conv2d(in_channels=32,out_channels=128,kernel_size=(3,3),padding=(1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dense_auto(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(dense_auto, self).__init__()\n",
    "        self.f_model = f_model\n",
    "        self.ae1 = ae1\n",
    "        self.hd1 = hd1\n",
    "        self.hd2 = hd2\n",
    "        self.ae1 = ae1\n",
    "        self.ae2 = ae2\n",
    "        self.r_model = r_model\n",
    "        self.r_freeze = r_freeze\n",
    "        self.r_model = r_model\n",
    "        self.cls_model = cls_model\n",
    "        self.cls_freeze = cls_freeze\n",
    "        self.zero_out = np.random.randint(0,16)\n",
    "        self.prob_zero = np.random.uniform(0,1,1)\n",
    "        \n",
    "    def forward_interpret(self,x):\n",
    "        x = hd1(x)\n",
    "        x[:,5,:,:] = 0\n",
    "        x = hd2(x)\n",
    "        return x\n",
    "    \n",
    "    def forward_shallow(self,x):\n",
    "        x = self.ae1(x)\n",
    "        y1 = x.clone()\n",
    "        x = self.forward_interpret(x)\n",
    "        y2 = x.clone()\n",
    "        x = self.ae2(x)\n",
    "        return x, y1,y2\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.f_model(x)\n",
    "        x2 = x.clone()\n",
    "        y, y1,y2 = self.forward_shallow(x)\n",
    "        y3 = y.clone()\n",
    "        features = self.r_model(x)\n",
    "        out = F.relu(features, inplace=True)\n",
    "        out = F.adaptive_avg_pool2d(out, (1, 1)).view(features.size(0), -1)\n",
    "        x = self.cls_model(out)\n",
    "        features_freeze = r_freeze(y)\n",
    "        out_f = F.relu(features_freeze, inplace=True)\n",
    "        out_f = F.adaptive_avg_pool2d(out_f, (1, 1)).view(features_freeze.size(0), -1)\n",
    "        y = cls_freeze(out_f)\n",
    "        return x, x2, y, y1, y2, y3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tvloss(yhat, y):\n",
    "    bsize, chan, height, width = y.size()\n",
    "    errors = []\n",
    "    dy = torch.abs(y[:,:,1:,:] - y[:,:,:-1,:])\n",
    "    dyhat = torch.abs(yhat[:,:,1:,:] - yhat[:,:,:-1,:])\n",
    "    error = torch.norm(dy - dyhat, 1)\n",
    "    return error / height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "save_path = \"causal_dense_zeroout_last2conv.pth\"\n",
    "def train_causal_model(c_model, optimizer, num_epochs=10):\n",
    "    best_model_wts = c_model.state_dict()\n",
    "    for epoch in range(num_epochs):\n",
    "        c_model.train(True)  # Set model to training mode\n",
    "        \n",
    "        running_loss = 0.0\n",
    "        test_loss = 10\n",
    "\n",
    "        for data in tqdm(dataloders):\n",
    "            inputs,labels = data\n",
    "            if use_gpu:\n",
    "                inputs = Variable(inputs.cuda())\n",
    "            else:\n",
    "                inputs = Variable(inputs)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            x,x2,y,y1,y2,y3 = c_model(inputs)\n",
    "#             loss_interpret = nn.CrossEntropyLoss()(y1,y2.detach().long())\n",
    "            loss_interpret = tvloss(y1,y2)\n",
    "            loss_ae = nn.L1Loss()(x2,y3.detach())\n",
    "            loss_kl = nn.KLDivLoss()(F.log_softmax(y,-1), x.detach())\n",
    "\n",
    "            loss = 5*loss_interpret + 2*loss_ae + 3*loss_interpret\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        epoch_loss = running_loss / dataset_sizes\n",
    "#         if epoch % 100 == 0:\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('Loss: {:.10f} '.format(epoch_loss))\n",
    "\n",
    "        # deep copy the model\n",
    "        if test_loss > epoch_loss:\n",
    "            test_loss = epoch_loss\n",
    "            best_model_wts = c_model.state_dict()\n",
    "            state = {'model':c_model.state_dict(),'optim':optimizer.state_dict()}\n",
    "            torch.save(state,save_path)\n",
    "\n",
    "    # load best model weights\n",
    "    c_model.load_state_dict(best_model_wts)\n",
    "    return c_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "causal_model = dense_auto().cuda()\n",
    "optimizer_c = optim.Adam(filter(lambda p: p.requires_grad,causal_model.parameters()), lr=0.001)\n",
    "for name, param in causal_model.named_parameters():\n",
    "#     if \"r_model\" in name:\n",
    "#         param.requires_grad = True\n",
    "    if param.requires_grad:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "train_causal_model(causal_model,optimizer_c,num_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "causal_eval = dense_auto().cuda()\n",
    "checkpoint = torch.load(\"causal_dense_zeroout.pth\")\n",
    "causal_eval.load_state_dict(checkpoint[\"model\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "def computingECE(causal_model,image):\n",
    "    img = Image.open(image).convert('RGB')\n",
    "    trans = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "    img = trans(img)\n",
    "    img.unsqueeze_(0)\n",
    "    img = img.cuda()\n",
    "    outputs = causal_model(img)\n",
    "    score = outputs[0][0]\n",
    "    print(torch.max(score,0))\n",
    "#     print(score)\n",
    "    \n",
    "    causal_score = outputs[2][0]\n",
    "    print(torch.max(causal_score,0))\n",
    "    causal_effect = causal_score - score\n",
    "#     print(causal_effect)\n",
    "    ece = torch.dot(causal_effect,score)\n",
    "    return ece\n",
    "image_path = \"database/original_images/00000001_000.png\"\n",
    "ece = computingECE(causal_model,image_path)\n",
    "ece"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OVERLAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import cv2\n",
    "import matplotlib.cm as cm\n",
    "def computingECE(causal_model,image):\n",
    "    img = cv2.imread(image,1)\n",
    "#     display = img\n",
    "    dx = img.shape[0] / 10\n",
    "    dy = img.shape[1] / 10\n",
    "    blocks = [12,22,23,32,33]\n",
    "    for channel in range(img.shape[2]):\n",
    "        for block in blocks:\n",
    "            img[int((block-1)*dx):int((block)*dx),int((block-1)*dy):int((block)*dy)] = 255\n",
    "    display = img\n",
    "    img = Image.fromarray(img)\n",
    "    trans = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "    img = trans(img)\n",
    "    img.unsqueeze_(0)\n",
    "    img = img.cuda()\n",
    "    outputs = causal_model(img)\n",
    "    score = F.softmax(outputs[0],1).view(-1)\n",
    "#     print(torch.max(score,0))\n",
    "#     print(score)\n",
    "    \n",
    "    causal_score = F.softmax(outputs[2],1).view(-1)\n",
    "#     print(torch.max(causal_score,0))\n",
    "    causal_effect = causal_score - score\n",
    "#     print(causal_effect)\n",
    "    ece = torch.dot(causal_effect,score)\n",
    "    return ece,display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"/home/jovyan/EJ/causality/CheXNet-Keras/data/masked_data/bbox/00007830_013.png\"\n",
    "ece,display = computingECE(causal_model,image_path)\n",
    "plt.imshow(display)\n",
    "ece"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FOOLBOX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "img_fool = Image.open(image_path).convert(\"RGB\")\n",
    "trans = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "img_fool = trans(img_fool)\n",
    "img_fool.cuda()\n",
    "print(\"img to cuda\")\n",
    "print(torch.max(img_fool))\n",
    "\n",
    "import foolbox\n",
    "from foolbox.models import PyTorchModel\n",
    "vgg_fool = models.vgg16(pretrained=True).eval()\n",
    "vgg_fool.cuda()\n",
    "\n",
    "fool_model = foolbox.models.PyTorchModel(vgg_fool, bounds=(-3,3), num_classes=1000)\n",
    "\n",
    "img_fool = img_fool.cpu().numpy()\n",
    "print(img_fool.shape)\n",
    "print(np.argmax(fool_model.predictions(img_fool)))\n",
    "label = np.argmax(fool_model.predictions(img_fool))\n",
    "\n",
    "# apply attack on source image\n",
    "attack = foolbox.attacks.FGSM(fool_model)\n",
    "adversarial = attack(img_fool, label)\n",
    "print('adversarial class', np.argmax(fool_model.predictions(adversarial)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
