{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import seaborn as sns\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "from tqdm import tqdm\n",
    "use_gpu = torch.cuda.is_available()\n",
    "torch.cuda.set_device(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATASETS & DATALAODER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/home/jovyan/EJ/causality/Caltech-Birds-Classification/train/\"\n",
    "trans = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "image_datasets = datasets.ImageFolder(data_dir,trans)\n",
    "dataloders = torch.utils.data.DataLoader(image_datasets, batch_size=8,\n",
    "                                             shuffle=True)\n",
    "dataset_sizes = len(image_datasets)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EVAL MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_eval = models.vgg16(pretrained=True).eval()\n",
    "if use_gpu:             \n",
    "    vgg_eval = vgg_eval.cuda()       \n",
    "vgg_eval = vgg_eval.float()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INTERVENE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 224, 224]           1,792\n",
      "              ReLU-2         [-1, 64, 224, 224]               0\n",
      "            Conv2d-3         [-1, 64, 224, 224]          36,928\n",
      "              ReLU-4         [-1, 64, 224, 224]               0\n",
      "         MaxPool2d-5         [-1, 64, 112, 112]               0\n",
      "            Conv2d-6        [-1, 128, 112, 112]          73,856\n",
      "              ReLU-7        [-1, 128, 112, 112]               0\n",
      "            Conv2d-8        [-1, 128, 112, 112]         147,584\n",
      "              ReLU-9        [-1, 128, 112, 112]               0\n",
      "        MaxPool2d-10          [-1, 128, 56, 56]               0\n",
      "           Conv2d-11          [-1, 256, 56, 56]         295,168\n",
      "             ReLU-12          [-1, 256, 56, 56]               0\n",
      "           Conv2d-13          [-1, 256, 56, 56]         590,080\n",
      "             ReLU-14          [-1, 256, 56, 56]               0\n",
      "           Conv2d-15          [-1, 256, 56, 56]         590,080\n",
      "             ReLU-16          [-1, 256, 56, 56]               0\n",
      "        MaxPool2d-17          [-1, 256, 28, 28]               0\n",
      "           Conv2d-18          [-1, 512, 28, 28]       1,180,160\n",
      "             ReLU-19          [-1, 512, 28, 28]               0\n",
      "           Conv2d-20          [-1, 512, 28, 28]       2,359,808\n",
      "             ReLU-21          [-1, 512, 28, 28]               0\n",
      "           Conv2d-22          [-1, 512, 28, 28]       2,359,808\n",
      "             ReLU-23          [-1, 512, 28, 28]               0\n",
      "        MaxPool2d-24          [-1, 512, 14, 14]               0\n",
      "           Conv2d-25          [-1, 512, 14, 14]       2,359,808\n",
      "             ReLU-26          [-1, 512, 14, 14]               0\n",
      "           Conv2d-27          [-1, 512, 14, 14]       2,359,808\n",
      "             ReLU-28          [-1, 512, 14, 14]               0\n",
      "           Conv2d-29          [-1, 512, 14, 14]       2,359,808\n",
      "             ReLU-30          [-1, 512, 14, 14]               0\n",
      "        MaxPool2d-31            [-1, 512, 7, 7]               0\n",
      "           Linear-32                 [-1, 4096]     102,764,544\n",
      "             ReLU-33                 [-1, 4096]               0\n",
      "          Dropout-34                 [-1, 4096]               0\n",
      "           Linear-35                 [-1, 4096]      16,781,312\n",
      "             ReLU-36                 [-1, 4096]               0\n",
      "          Dropout-37                 [-1, 4096]               0\n",
      "           Linear-38                 [-1, 1000]       4,097,000\n",
      "================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 218.59\n",
      "Params size (MB): 527.79\n",
      "Estimated Total Size (MB): 746.96\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "vgg_test = models.vgg16(pretrained=True)\n",
    "if use_gpu:                                 # if gpu is available then use it\n",
    "    vgg_test = vgg_test.cuda()       \n",
    "vgg_test = vgg_test.float()\n",
    "summary(vgg_test,(3,224,224))\n",
    "# vgg_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODIFY MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "freeze_layer = 9\n",
    "f_model = list(vgg_test.features.children())[:freeze_layer]\n",
    "f_model = nn.Sequential(*f_model)\n",
    "r_model = list(vgg_test.features.children())[freeze_layer:len(list(vgg_test.features.children()))]\n",
    "r_model = nn.Sequential(*r_model)\n",
    "cls_model = nn.Sequential(*list(vgg_test.classifier.children()))\n",
    "r_freeze = list(vgg_test.features.children())[freeze_layer:len(list(vgg_test.features.children()))]\n",
    "r_freeze = nn.Sequential(*r_freeze)\n",
    "cls_freeze = nn.Sequential(*list(vgg_test.classifier.children()))\n",
    "\n",
    "for param in r_freeze.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in cls_freeze.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae1 = nn.Conv2d(in_channels=128,out_channels=32,kernel_size=(3,3),padding=(1, 1))\n",
    "hd1 = nn.Conv2d(in_channels=32,out_channels=16,kernel_size=(3,3),padding=(1, 1))\n",
    "hd2 = nn.Conv2d(in_channels=16,out_channels=32,kernel_size=(3,3),padding=(1, 1))\n",
    "ae2 = nn.Conv2d(in_channels=32,out_channels=128,kernel_size=(3,3),padding=(1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class vgg_auto(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(vgg_auto, self).__init__()\n",
    "        self.f_model = f_model\n",
    "        self.ae1 = ae1\n",
    "        self.hd1 = hd1\n",
    "        self.hd2 = hd2\n",
    "        self.ae1 = ae1\n",
    "        self.ae2 = ae2\n",
    "        self.r_model = r_model\n",
    "        self.r_freeze = r_freeze\n",
    "        self.r_model = r_model\n",
    "        self.cls_model = cls_model\n",
    "        self.cls_freeze = cls_freeze\n",
    "        self.zero_out = np.random.randint(0,16)\n",
    "        self.prob_zero = np.random.uniform(0,1,1)\n",
    "        \n",
    "    def forward_interpret(self,x):\n",
    "        x = hd1(x)\n",
    "        x = hd2(x)\n",
    "        return x\n",
    "    \n",
    "    def forward_shallow(self,x):\n",
    "        x = self.ae1(x)\n",
    "        y1 = x.clone()\n",
    "        x = self.forward_interpret(x)\n",
    "        y2 = x.clone()\n",
    "        x = self.ae2(x)\n",
    "        return x, y1,y2\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.f_model(x)\n",
    "        x2 = x.clone()\n",
    "        y, y1,y2 = self.forward_shallow(x)\n",
    "        y3 = y.clone()\n",
    "        x = self.r_model(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.cls_model(x)\n",
    "        y = r_freeze(y)\n",
    "        y = y.view(y.size(0), -1)\n",
    "        y = cls_freeze(y)\n",
    "        return x, x2, y, y1, y2, y3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tvloss(yhat, y):\n",
    "    bsize, chan, height, width = y.size()\n",
    "    errors = []\n",
    "    dy = torch.abs(y[:,:,1:,:] - y[:,:,:-1,:])\n",
    "    dyhat = torch.abs(yhat[:,:,1:,:] - yhat[:,:,:-1,:])\n",
    "    error = torch.norm(dy - dyhat, 1)\n",
    "    return error / height"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAIN FUNC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"causal_fine_overlap.pth\"\n",
    "def train_causal_model(c_model, optimizer, num_epochs=10):\n",
    "    best_model_wts = c_model.state_dict()\n",
    "    for epoch in range(num_epochs):\n",
    "        c_model.train(True)  # Set model to training mode\n",
    "        \n",
    "        running_loss = 0.0\n",
    "        test_loss = 10\n",
    "\n",
    "        for data in dataloders:\n",
    "            inputs,labels = data\n",
    "            if use_gpu:\n",
    "                inputs = Variable(inputs.cuda())\n",
    "            else:\n",
    "                inputs = Variable(inputs)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            x,x2,y,y1,y2,y3 = c_model(inputs)\n",
    "#             loss_interpret = nn.CrossEntropyLoss()(y1,y2.detach().long())\n",
    "            loss_interpret = tvloss(y1,y2)\n",
    "            loss_ae = nn.L1Loss()(x2,y3.detach())\n",
    "            loss_kl = nn.KLDivLoss()(F.log_softmax(y,-1), F.softmax(x,-1).detach())\n",
    "\n",
    "            loss = 5*loss_interpret + 2*loss_ae + 3*loss_interpret\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        epoch_loss = running_loss / dataset_sizes\n",
    "#         if epoch % 100 == 0:\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('Loss: {:.10f} '.format(epoch_loss))\n",
    "\n",
    "        # deep copy the model\n",
    "        if test_loss > epoch_loss:\n",
    "            test_loss = epoch_loss\n",
    "            best_model_wts = c_model.state_dict()\n",
    "            state = {'model':c_model.state_dict(),'optim':optimizer.state_dict()}\n",
    "            torch.save(state,save_path)\n",
    "\n",
    "    # load best model weights\n",
    "    c_model.load_state_dict(best_model_wts)\n",
    "    return c_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "causal_model = vgg_auto().cuda()\n",
    "optimizer_c = optim.Adam(filter(lambda p: p.requires_grad,causal_model.parameters()), lr=0.001)\n",
    "# for name, param in causal_model.named_parameters():\n",
    "#     if \"r_model\" in name:\n",
    "#         param.requires_grad = True\n",
    "#     if param.requires_grad:\n",
    "#         print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/2\n",
      "Loss: 41.7687948142 \n",
      "Epoch 1/2\n",
      "Loss: 0.0435308144 \n",
      "Epoch 2/2\n",
      "Loss: 0.0392419569 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "vgg_auto(\n",
       "  (f_model): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace)\n",
       "  )\n",
       "  (ae1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (hd1): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (hd2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (ae2): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (r_model): Sequential(\n",
       "    (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (2): ReLU(inplace)\n",
       "    (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): ReLU(inplace)\n",
       "    (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace)\n",
       "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (8): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace)\n",
       "    (10): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace)\n",
       "    (12): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace)\n",
       "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (15): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (16): ReLU(inplace)\n",
       "    (17): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace)\n",
       "    (21): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (r_freeze): Sequential(\n",
       "    (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (2): ReLU(inplace)\n",
       "    (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): ReLU(inplace)\n",
       "    (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace)\n",
       "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (8): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace)\n",
       "    (10): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace)\n",
       "    (12): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace)\n",
       "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (15): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (16): ReLU(inplace)\n",
       "    (17): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace)\n",
       "    (21): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (cls_model): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace)\n",
       "    (2): Dropout(p=0.5)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace)\n",
       "    (5): Dropout(p=0.5)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       "  (cls_freeze): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace)\n",
       "    (2): Dropout(p=0.5)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace)\n",
       "    (5): Dropout(p=0.5)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_causal_model(causal_model,optimizer_c,num_epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FOOL BOX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img to cuda\n",
      "tensor(2.6400)\n",
      "(3, 224, 224)\n",
      "17\n",
      "adversarial class 89\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "image_path = \"train/n01580077/63.jpg\"\n",
    "\n",
    "img_fool = Image.open(image_path)\n",
    "trans = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "img_fool = trans(img_fool)\n",
    "# img_fool.unsqueeze_(0)\n",
    "img_fool.cuda()\n",
    "print(\"img to cuda\")\n",
    "# img_fool = img_fool.cpu().numpy()\n",
    "print(torch.max(img_fool))\n",
    "\n",
    "import foolbox\n",
    "from foolbox.models import PyTorchModel\n",
    "vgg_fool = models.vgg16(pretrained=True).eval()\n",
    "vgg_fool.cuda()\n",
    "\n",
    "fool_model = foolbox.models.PyTorchModel(vgg_fool, bounds=(-3,3), num_classes=1000)\n",
    "\n",
    "img_fool = img_fool.cpu().numpy()\n",
    "print(img_fool.shape)\n",
    "print(np.argmax(fool_model.predictions(img_fool)))\n",
    "label = np.argmax(fool_model.predictions(img_fool))\n",
    "\n",
    "# apply attack on source image\n",
    "attack = foolbox.attacks.FGSM(fool_model)\n",
    "adversarial = attack(img_fool, label)\n",
    "print('adversarial class', np.argmax(fool_model.predictions(adversarial)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CAUSAL EFFECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import cv2\n",
    "import matplotlib.cm as cm\n",
    "def computingECE(causal_model,img):\n",
    "    img = Image.fromarray(img.astype('uint8'), 'RGB')\n",
    "    trans = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "    img = trans(img)\n",
    "    img.unsqueeze_(0)\n",
    "    img = img.cuda()\n",
    "    outputs = causal_model(img)\n",
    "    score = F.softmax(outputs[0],1).view(-1)\n",
    "    print(torch.max(score,0))\n",
    "#     print(score)\n",
    "    \n",
    "    causal_score = F.softmax(outputs[2],1).view(-1)\n",
    "    print(torch.max(causal_score,0))\n",
    "    causal_effect = causal_score -score\n",
    "#     print(causal_effect)\n",
    "    ece = torch.dot(causal_effect,score)\n",
    "    return ece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(1.00000e-02 *\n",
      "       1.0051, device='cuda:2'), tensor(812, device='cuda:2'))\n",
      "(tensor(1.00000e-02 *\n",
      "       1.3776, device='cuda:2'), tensor(892, device='cuda:2'))\n"
     ]
    }
   ],
   "source": [
    "image_path = \"train/n01531178/62.jpg\"\n",
    "ece = computingECE(causal_model,adversarial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.00000e-04 *\n",
       "       -2.8862, device='cuda:2')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
